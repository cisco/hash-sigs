These are some notes about the internal programming style of the HSS
subsystem.  These are of no interest to someone who just wants to use LMS
signatures; they might give some insight to someone spelunking through the
sources.

- General philosophy
  This subsystem implements the HSS siganture scheme, which is a moderately
  complex data structure, involving multiple Merkle trees.  To make things
  even more fun, we implement restarting, that is, loading a private key
  into memory, even if that private key has already generated some signatures
  (and constructing the Merkle tree structures to reflect those signatures),
  and multithreading (that is, we can spread many of the computations over
  multiple processors).
  Now, there is a rather annoying amount of complexity within the package;
  we strive to isolate that from the user.  When the user creates a private
  key, he has to tell us the parameter set (we can't make that up ourselves);
  however, after that, he just loads the keys, and signs messages, without
  worrying about the internal structure of the trees.  The parts that we
  do leave to the user (such as the functions to load/store the private key)
  are there in attempt to make it easier to use the system securely.

- Configuation file config.h
  This file contains a set of tweakable parameters that the application may
  want to customize for its use (and hardware platform).  Here are the current
  flags:
  MAX_THREAD This is the maximum number of child threads we will ever try
          to spawn.
  DEFAULT_THREAD This is the number of child threads we can attempt to spawn
          if the application doesn't tell us otherwise.
  FAULT_CACHE_SIG If this flag is set, then his package attempts to implement
          protection against fault injectio attacks; it works by hashing the
          internal signatures (when they are first computed) and storing them
          in the private key; if we later recompute them, we check to see if
          they have changed (and if so, we declare an error).  If you have an
          attacker that can plausibly make you miscompute something, this (or
          the next one) is of interest.  Turning this on does increase the
          size of the private key; in addiiton, if you're doing autoreserve,
          this may increase the number of times we update the private key.
          This is fairly cheap, and so this is turned on in the release
          package (and you can turn it off, if you want).
  FAULT_CACHE_LEN If FAULT_CACHE_SIG is set, then this determines the size of
          the hash we store in the private key; larger values make it harder
          for an attacker that can precisely target faults to get one past
          this logic; smaller values use up less room in the private key.
  FAULT_RECOMPUTE If this flag is set, then this package attempts to implement
          protection against fault injectio attacks; it works by computing the
          public keys and internal signatures twice (and indepdently); if they
          don't match, then an error is declared. If you have an attacker
          that can plausibly make you miscompute something, this (or the
          previous one) is of interest.  Turning this on does increase the
          time taken and the memory used.
  SECRET_METHOD This controls how seeds are generated
          Note that changing this (or SECRET_MAX) will invalidate any existing
          private keys.
          0 -> Use the algorthm defined in Appendix A of the draft
          1 -> Use a side channel resisteant process which limits the number
               of distint hashes a secret value is used in.
  SECRET_MAX If SECRET_METHOD==1, this we limit the number of hashes a secret
               is sed with to 2**SECRET_MAX
  USE_OPENSSL This defines whether we attempt to link to OpenSSL (only the
          SHA256 implementation), or whether we use a slower portable C
          version
  ALLOW_VERBOSE If set, we insert debugging code that, if the global
          hss_verbose is also set, we print out hash inputs and outputs.
          This works only if USE_OPEN_SSL==0.
          Obviously, this is not something you want to do on delivered code,
          and is *really* chatty (and I'd recommend you turn off
          multithreading during the test).
  TEST_INSTRUMENTATION If set, we insert instrumentation code.  Currently,
          the only instrumentation is to test mallocs and to delibberately
          introduce faults into the hash functions (to test out the fault
          protection code).  Obviously, the latter is not something you want
          to do on delivered code,

- Merkle trees, subtrees
  The core of this system is the signer, and the working key.  To sign
  a message, we generate the OTS signature for that message, and generate
  the authentication path to the root; this authentication path are the
  nodes adjacent to the actual path from the OTS public key to the Merkle
  tree root; hence when we generate the signature, we need to have those
  internal node values computed.  We could compute them on the fly, but
  that's be expensive.  We could store the entire Merkle tree in memory
  and retrieve them that way, but that'd take too much memory (for H-25,
  that's 2Gigabytes) [1].  Instead, what we do is implement a Merkle tree
  walk, which recomputes a few OTS public keys (and Merkle internal nodes)
  per signature, and ensures that we have the data needed for the
  authentication path when we need them.  The algorithm we actually use for
  this is inspired by the paper "Fractal Merkle Tree Representation and
  Traversal", by Jakobsson et al.  Now, we don't do the exact algorithm
  found in the paper (Algorithm 3); we go for "constant OTS pubkey
  computation", and not "constant hash evaluations" (the algorithm in the
  paper assumes that generating a leaf node takes one hash; it's more
  like a few thousand).  In addition, we need to deal with the complexity
  of dealing with multiple trees at once, their algorithm considers only
  one.  If you do go through the paper, their $Exist_i$ tree is our
  ACTIVE_TREE, and their $Desire_i$ tree is our BUILDING_TREE (and they
  don't have a NEXT_TREE).  This algorithm allows a time/memory trade-off,
  and even if we don't give it much memory, it's still decently efficient.
  This algorithm is based on a "subtree"; a subtree is a triangular subsection
  of the tree that consists of nodes from level A to level A+h-1 of the tree
  which are rooted by a specific level A node; 'h is the height of the
  subtree.  If the Merkle tree is level H, then we divide up the tree into H/h
  (rounded up) levels, and deal with the subtrees at each levels (if h doesn't
  divide H cleanly, then the top level subtree will be shorter).  For each
  such level, we track an ACTIVE_TREE, a BUILDING_TREE and a NEXT_TREE
  (exceptions: the top-most subtree doesn't get a BUILDING_TREE, and the
  subtrees for the top level Merkle tree don't get NEXT_TREE's; they wouldn't
  be used).
  The ACTIVE_TREE lives on the current authentication path (that is, on the
  path from the current (actually, next-to-be-used) leaf node to the Merkle
  tree root.  The ACTIVE_TREE is always fully populated (that is, it contains
  the correct value for all the internal nodes within the subtree), and so we
  can read the authentication path by looking at the nodes within the
  ACTIVE_TREE.
  The BUILDING_TREE is the subtree to the immediate right of the ACTIVE_TREE,
  within the same Merkle tree.  That is, the root of the BUILDING_TREE is the
  node next to the root of the ACTIVE_TREE.  As we generate signatures from
  the ACTIVE_TREE, we also incrementally compute nodes in the BUILDING tree.
  If the root of the two subtrees are height L from the leaf nodes, then we
  generate 2**L signatures from the current ACTIVE_TREE, and we need 2**L
  OTS pubkey generations to fully build the BUILDING tree; hence for each
  signature generated, we compute one OTS pubkey (and do the other work
  involved with constructing the tree); when we complete the ACTIVE_TREE,
  the BUILDING_TREE is all constructed, and ready to become the new active.
  We need to do this update 1 time for each building tree in the bottom
  merkle tree; there are H/h-1 (rounded up) such levels (the topmost
  subtree doesn't get a building tree, as there's no subtree adjacent
  to it), and so the building subtrees involve H/h-1 OTS pubkey gens.
  The NEXT_TREE is the first subtree that's in the next Merkle tree.  Except
  for the topmost Merkle level, when we exhaust one Merkle tree, we're
  expected to roll over to the next.  The NEXT_TREE is there so that when
  we do, we'll have a fresh set of ACTIVE_TREEs are ready to go.  If the
  height of the Merkle tree is H, then the current Merkle tree can sign
  2**H signatures, and it takes 2**H OTS pubkey gens to construct the
  next Merkle tree, hence we do one OTS pubkey gen for the next tree
  per signature (in addition to the building tree pubkey gens listed
  above).
  Also, cryptographically, all levels of the HSS hierarchy are the same, but
  from an implementation standpoint, they're not.  Almost all the work
  computing the next authentication path is done with the bottom level Merkle
  tree, and so if the user allows us extra memory, we'll devote all that
  memory to expanding the bottom subtrees (which reduces the number of OTS
  pubkey computations per signature; by increasing h, we decrease H/h).  For
  Merkle trees other than the bottommost, we always use the subtree height
  that gives us the minimal memory (which isn't always the smallest subtrees)
  [2].  Because we hardly ever need to update the subtrees there, any extra
  memory we use would be wasted.
  Another difference between the bottom-most Merkle tree and higher trees
  is the update strategy.  For the bottom-most Merkle tree, we perform the
  needed OTS pubkey gens as a part of the signature call (as that's the only
  time we have to perform any operations).  However, for higher level trees,
  we don't gen those OTS pubkeys when we generate the signature (as that
  would cause that signature to be unexpectedly expensive); instead we
  spread the OTS pubkey gens over a number of previous signature operations.
  Also, we deliberately do those when the bottom-most tree is doing fewer
  operations than expected (e.g. one of its ACTIVE_TREEs is on the right
  side, and so there's no need for us to update the BUILDING_TREE), and so
  the caller doesn't see any unexpected expense at all.
  A third difference (if fault recomputation is on) is that we don't keep a
  redundant copy of the top level LMS tree.
  When we load a private key in memory, the bulk of the work is initializing
  the subtrees to be what we'd expect them to hold, based on what the current
  count is.  Actually, we advance the building and next trees to be slightly
  in advance of what they'd be if we incremented them manually (that turns
  out to be somewhat simpler).

  [1] Actually for the bottom level Merkle tree, if the user allows us enough
  memory, we will explicitly represent the entire Merkle tree in memory; we
  just have it implement one huge subtree, that is, H=h.  However, we don't
  mandate that the user allow us that much memory, if he allows us less,
  we'll go with a more compact (and slower) representation.
  [2] Except in those cases where the immediately below Merkle tree won't
  give us enough updates, which can happen only in rather obscure parameter
  sets, e.g. 25/5.

- Aux data; what is it, really?

  When we first generate the public key, we must compute the entire Merkle
  tree contents for the top level Merkle tree (in order to compute the public
  key).  When we load the private key into memory, we must compute the
  authentication path for active Merkle trees (which includes the top level
  one); this involves computing the entire Merkle tree contents.  Obviously,
  there is a lot of repeated computation going on; our answer to that it
  auxiliary data.  When we generate the Merkle tree the first time (when we
  generate the public key), we save some of the contents of this tree; when we
  load the key into memory, we use these saved contents (rather than
  recomputing those nodes); this significantly decreases the amount of
  recomputation we need.  We actually save the values at the bottom of the
  subtrees; that means that those bottom nodes for the subtrees we've saved
  are free; we recompute the internal nodes for those subtrees ourselves (but
  that's comparatively cheap).  The higher level subtrees cost us the least
  amount of disk space (there are fewer of them), and they save us the most
  computation time, and so those get priority.  We know (given the current
  allocation algorithm) what subtree heights would be (and hence where their
  bottom levels would be; based on the amount of aux data we're allowed, we'll
  save as many bottom levels as can fit.
  Also, we protect the aux data with an HMAC (and if that doesn't validate on
  reload, we ignore it); this means that an attacker can't cause us to
  generate invalide signatures by message with the aux data; they can make
  key reloading take more time.

- Extra info, what's up with that?
  There are some information that the application may want to specify, but
  most applications really don't care.  Some examples are "how many threads
  should I use", or "have we just signed the last signature?" or "why did
  that call just fail?".  Instead how having independant parameters for each
  one (and having to modify the API every time we think of another one), we
  bundled them all into a structure (struct hss_extra_info), and allow the
  application to set it, pass in a pointer to it, and on return, check the
  results.  Of course, if the application is OK with the defaults, it can
  just pass in a NULL.  Currently, we have three things that can be passed:
  - Number of threads that we can use
  - Whether we just used up the last signature
  - Most recent failure reason (hss_error_code, you'll see that there are
    a lot of possible reaosns)
  In the future, we'll likely to add support for partial trees, and possibly
  other things we haven't thought of yet; one nice thing is that we can add
  something here to add an obscure (== "not of interest to most applications")
  parameter without modifying the API to existing applications.

- Data structures; this is a review of some of the structures used within
  this subsystem, and what they really mean
  private key
      This is what the raw private key looks like.  It's not a formal C
      structure; instead, it is a byte array, split up into:
      - 3 bytes of key format; this is to allow us to modify the key format
        in the future, without causing disasters if someone tries to load
        a previous key format.  The 3 bytes are:
           0x01 - The current format
           SECRET_MAX - The SECRET_MAX this key was generated with; 0xff
                   if SECRET_METHOD == 0
           FAULT_CACHE_LEN - The FAULT_CACHE_LEN this key uses; 0x00 if
                   FAULT_CACHE_SIG == 0
      - 1 byte of L; the number of tree levels in the HSS structure; between
        1 and 8
      - 8 bytes of count; this is the state that gets updated with every
        signature, and consists of a bigendian count of the number of
        signatures so far.  By convention, a setting of 0xffffffffffffffff
        means 'we're used up all our signatures'.
      - 8 bytes of checksum; this is the first 8 bytes of the SHA-256 of
        the private key (skipping the checksum).  This is here to detect
        when the private key is corrupted.  It can't detect rollbacks or
        malicious modifications of the private key; it will detect
        accidental ones
      - (L-1) * FAULT_CACHE_LEN of hashed signed public keys; when we
        generate a signed public key (and it is possible that, on a
        key reload, we'll recreate that signed public key), we'll hash
        the signed public key, and place the first FAULT_CACHE_LEN bytes
        here (with the lowest level public key being the first).  The
        public keys here are from the count listed in the count field
        above (which might be in front of the count in the working key
        if there is a reservation active).  Not present if
        FAULT_CACHE_SIG == 0
      - 8 bytes of max count; this is the maximum value that we'll allow
        for the count.  This is here so that, in the future, we can issue
        private keys that are of limited range (the deligated subkey idea)
      - L bytes of parameter set, in a compressed format.  This is here so
        that the application needn't tell us what the parmaeter set when
        loading a key (and can't get it wrong)
      - 32 bytes of random seed; this is where all the security comes from.
        It is 32 bytes (256 bits) so Grover's algorthm can't recover it.
      This is a flat set of bytes, because we hand it to read_private_key
      and update_private_key routines, which are expected to read/write
      them to long term storage.  This key is a total of
      52 + L*(FAULT_CACHE_LEN+1) bytes long.
      We put things in this order to place the frequently modified fields
      up front.  Hence, if we need to update the hashed signatures, we're
      able to ask the NV write routine to update a minimal number of bytes
      (of course, the NV write routine may decide just to update the entire
      key; we're just giving the NV write the option).
  struct hss_working_key
      This structure holds all the current state of a loaded private key.
      It contains a copy of the private key (so we can write it out as
      required; we have the entire thing in memory, in case the write
      routine isn't able to do a partial update), the current and reserve
      counts (the reserve count is what we've last written to the private
      key; we use it to implement the 'reserve' functionality), the
      current signed public keys that we place into the signature,
      and all the levels that make up this hierarchy.
      One nonobvious member of this structure is 'stack'.  Some of the
      subtrees (the nonbottom building and next subtrees) require a
      stack to hold intermediate hash values (as we compute them one
      OTS pubkey at a time).  On the other hand, other subtrees (the
      active ones) have no such need; so, to save a bit of space, we
      consolidate all the stacks into one contiguous region (and have
      each subtree point into the part of the region that's theirs).
      And, when we swap the active subtree with a building/next, we move
      the stack pointer from the old building/next subtree to the new
      (as the new active one doesn't need it).
      In addition, the tree[redux][level] points to the tree level
      data structure; for redux == 1, this points to the redundant
      tree level (for fault hardening).  We also special case
      tree[0][0] == tree[1][0], as the top level tree needn't be
      redundant (as we never sign its public key).
  struct merkle_level
      Actually, this is not a Merkle tree (even though the code typically
      names variables of this type 'tree').  Instead, it stands for a
      specific tree level within the HSS hierarchy, and all the trees
      that might live at that level.  It contains the parameter set
      that is used for this level, how the trees are implemented (subtree
      sizes), and also two different trees at this level; the one the active
      path is going through, and the next tree that will be used at this
      level (once the current tree all the signatures it is allowed).  This
      structure has pointers to the various subtrees that hold the known node
      values for the two trees.
  struct subtree
      This contains the node values for a particular subtree.  The
      height of this subtree is implicit (we use values in the merkle_level
      to recompute it), it does contain the location of the subtree within
      the larger tree.  There are three different flavors of subtrees,
      active, building and next; we tell which one this is based on
      the pointer from the merkle_level.  For building and next subtrees,
      the subtree may not be complete; the current_index value tells
      us where in the building process we are.  For nonbottom subtrees,
      this building process involves a stack (to combine nodes that
      are lower than the bottom of this subtree); the stack member is
      a pointer to a region dedicated for this rebuild for this subtree.
      The actual node values are in the array nodes[] (and the structure
      will be malloc'ed large enough to hold all the nodes); the root
      of the subtree will be at location 0.
  struct thread_collection
      This is the abstract structure that stands for a collection of threads.
      Its contents are specific to the actual threading implementation (the
      trivial implementation doesn't actually bother defining it, as it never
      allocates an object of this type).  It holds information about the
      threads, any necessary locks, and the tasks that have been asked for.
      In addition, any such pointer to a (struct thread_collection) may be
      NULL; this is never considered an error condition, rather it is an
      indication that we're running in single-threaded mode (either because
      that's how we're linked, or because we got an error spawning the
      thread).
  struct expanded_aux_data
      This is an array of pointers to the various node values that occur
      at various sublevels within the aux data; for any level that isn't
      stored in the aux data, the pointer will be NULL.  This will always
      point into an application provided buffer, hence we don't need to
      worry about memory allocation.
      This is used in two slightly different ways: if we're building the
      aux data (during key generation time), this will point to where the
      aux data should go (that is, into the application-provided buffer).
      If we're loading the aux data (during key load time), this will point
      into where in the buffer the various levels actually are (and if the
      buffer doesn't validate (wrong length or bad HMAC), we NULL out all
      the pointers (and so the generation code treats it as if we had no
      aux data).

- Types
  We try to use types in a stereotypical way; we do this not so much to allow
  the compiler to do type checking (as most of the types of flavors of int,
  which the compiler will allow to mix-and-match freely), intead, it's
  intended as a hint to the maintainer what this variable is supposed to be.
  Of course, it counts as a hint only if the reader actually knows what we use
  which types for :-)
  sequence_t
     This is the internal sequence number across an entire HSS tree structure.
     That is, it's used to represent the total number of signatures that an
     HSS private key has signed so far.  This is a 64 bit type, as we allow
     parameter sets that can sign more than 2**32 signatures.
  merkle_index_t
     This is the 'index' within a single Merkle tree; however we do give it
     four distinct meanings:
     - This is the count of the number of signatures generated with a single
       Merkle tree so far
     - The 'address' of a Merkle node that we use when computing its hash;
       that is, the four bytes we include in the hash.  In the draft, the
       variable 'r' is this type.
     - The offset of a node from the left side of the Merkle tree.  In the
       draft, the variable 'q' in the OTS signatures is this type, however we
       use it for internal nodes within the Merkle tree as well.
     - The offset of a node from the left side of the subtree it is in.  This
       is different from the previous definition if the subtree we're in isn't
       the leftmost.  Obviously, this meaning is never referenced in the draft
       (as the draft never discusses subtrees).
     If we were doing a rewrite, we'd probably give different typedef's for
     the distinct meanings.
  size_t
     This is the size of an object (buffer, signature, whatever).  Two notes:
     - If we know that the size cannot be greater than 65535 (e.g. the size
       of a hash), we sometimes use 'unsigned' instead
     - In a couple of places, we want the size, however we want to allow
       negative values as well.  In those places, we use the type
       'signed long' (and, yes, I know that 'signed' is redundant; I want
       to emphesize the signedness).
  bool
     We use a bool in two different ways; the first is the obvious (a value
     which is true or false); the other is a success value (did the operation
     work or not?); we use the convention "true == it worked",
     "false == it failed".  It might make sense to use the opposite convention
     (0 means it worked, nonzero means it failed; the exact nonzero value
     might give an indication as to why it failed); however to me, having
     0 meaning success is sufficiently nonintuitive that I just can't do it;
     we have added another way to communicating the failure reason to the
     application, in case it cares.
  param_set_t
     This is either an LM or an OTS parameter set (32 bits).
  aux_level_t
     This is the 32 bit flag that goes in front of the auxilary data; bits
     within this flag indicate which Merkle tree levels we actual have
     auxilary data for (and whether we have any aux data at all).  If the
     msbit of the initial byte of the aux data (which corresponds to bit 31
     of the aux_level_t) is clear, then we assume we have no aux data (even
     if the aux data consists of only that one byte; that means for any
     real aux_level_t, bit 31 will be set.
   hss_error_code
     This is the code that stands for an error reason; for some structures,
     we also use this as a 'is-this-structure-usable' flag (with something
     other than "no error" (hss_error_none) meaning 'if someone tries to
     use this structure, report this error'.
     We've divided the various error codes into ranges, to stand for the
     general types of errors (essentially, who we think was at fault):
     - hss_range_normal_failures; these are the types of errors you get
           when running the package normally (signature validation failure,
           private key expired)
     - hss_range_bad_parameters; these are the types of errors caused by
           the application misusing the package (unsupported parameter set,
           passed buffer not big enough, etc)
     - hss_range_processing_error; these are errors caused by something in
           the environment (rng failure, nvread/write failure, malloc
           failure)
     - hss_range_my_problem; these are errors caused by something internal
           to this package; currently, they're either hss_error_internal,
           caused by either something scribbling over our memory
           or a bug somewhere; or hss_error_fault_detected (the fault
           detection logic detected a miscompute).
   struct seed_derive
     This is the structure we use to derive keys in a potentially side
     channel resistant manner.  There are two different versions of this
     structure (with the same API, controlled by #define's) that map
     the current seed, I value, q value (Merkle tree node index) and
     j value (Winternitz digit index) into unpredictable values for the
     LM-OTS private values (and the C values and the child tree I, seed
     values).  We make this into a structure because, when we're doing
     a tree based derivation method (SECRET_METHOD==1), adjacent values
     usually share most of the nodes of the tree, and this structure is
     a convienent place to store those shared values (allowing us to
     avoid recomputation).
     This structure is used as follows:
     - hss_seed_derive_init to set the I, seed values
     - hss_seed_derive_set_q to set the q value (and if you call this again
       to set it to a different q value, this tries to reuse as many nodes
       as possible to minimize computation
     - hss_seed_derive_set_j to set the initial j value.
     - hss_seed_derive to get the next seed value.  If increment_j is set,
       this also sets up the structure for the next j value, and in a way
       that minimized the number of hashes done.
     - hss_seed_derive_done when we're done (to zeroize any internal state
       information).
    The programmer can modify the SECRET_METHOD/SECRET_MAX settings to
    change the efficiency/side channel resistance mix; however any
    such change modifies the mapping between seeds and private LM-OTS
    values (that is, your existing private keys no longer work).

- Side channel resistance and key derivation.
  We are inherently resistant to timing and cache-based side channel attacks
  (as those behaviors are uncorrelated to any secret information).  However,
  when we come to DPA-style attacks, we do try to have some protection.  To
  perform a DPA attack, the attacker would need to see us use the same secret
  value in a number of distinct hashes (which would allow them to build up
  the statistics).  To prevent this from being a problem, we can be configured
  so that no secure is ever used for more than a limited number of hashes
  (and so the attacker cannot get enough information to reconstruct any
  secret).  This is controlled by the SECRET_METHOD and SECRET_MAX #defines
  found in hss_derive.h.  SECRET_METHOD==0 means that we don't worry that much
  (and we use the LM-OTS key generation procedure found in Appendix A).
  SECRET_METHOD==2 means that we use the same procedure that ACVP expects to
  translate seed values to the random values used. It's a variation of the
  SECRET_METHOD==0 method, and isn't designed to be side-channel resistant.
  SECRET_METHOD==1 means that the number of times we use any secret is
  bounded to a maximum of 2**SECRET_MAX times.  In this method, we derive
  keys using a tree-based process, with each node having up to 2**SECRET_MAX
  children.  Decreasing SECRET_MAX takes a bit more time (as the tree becomes
  deeper), however even SECERET_MAX==1 (smallest allowed value) isn't that
  expensive.

- Protection against Fault attacks
  One concern is that if we were to miscompute a hash (and hence miscompute
  an LMS public key), we might end up signing one public key with the parent
  OTS key, and then at a different time, compute it correctly, and thus sign
  a different public key with the same OTS key.  This issue was first raised
  by https://eprint.iacr.org/2018/674.pdf in the context of Sphincs; the same
  concern is valid here.
  This package implements optional protection against this fault attack,
  enabled by the FAULT_RECOMPUTE or the FAULT_CACHE_SIG flags.  We actually
  implement two separate protections; the user can choose to use either or
  both.  BTW: why did we bother with two separate methods?  Well, I first
  implemented the FAULT_RECOMPUTE method; after that work was done, I realized
  that the FAULT_CACHE_SIG method would also work (and be cheaper), and so I
  implemented that (and had no good reason to back out the FAULT_RECOMPUTE
  code).
  If the FAULT_CACHE_SIG flag is set, then the first time we generate an
  signed public key (to insert into an HSS signature), we store a hash of that
  signed public key in the private key; if we ever regenerate it (because of a
  reload), we'll compare the new hash with what's in the private key (and fail
  if they differ).  One exception, if we generate a signed public key and find
  that we'll never recreate it (because the current reservation covers the
  entire use of that public key), we won't write it.
  If the FAULT_RECOMPUTE flag is set, we will redundently recompute the LMS
  public keys (other than the top one), and if they get out of sync, fail.
  Because a fault attack works by having two different public keys signed by
  the same OTS private key, either of these methods protect against this.
  You enable this protection by setting either the FAULT_RECOMPUTE or the
  FAULT_CACHE_SIG in config.h to 1 and recompiling (or you could turn on
  both, if you are extra paranoid, and don't mind both costs).
  The costs of FAULT_CACHE_SIG: this increases the size of the private key.
  In addition, if you're using the autoreserve feature (to decrease the
  number of writes to NVRAM), this may increase it somewhat (because sometimes
  we'll need to update the hsahes in the private key, even when our
  reservation isn't quite up yet.  However, the additional computational costs
  are minimal.
  The costs of FAULT_RECOMPUTE: we increase both the signature generation
  time (althogh multithreading helps here; we place the additional
  computation into additional threads) and key load time (multithreading
  doesn't help - we already max out the number of threads), and we
  increase our memory footprint somewhat.  Note that if you use L=1, then
  fault attacks aren't actually a concern (and you also don't get charged
  the additional computational costs).
  
- Threading architecture
  We support doing operations on multiple threads, however we'd rather not
  have the majority of the code know whether we're actually doing threading
  or not.  The compromise we came up with is the hss_thread.h API; this
  compromise is not perfect (at least half of the complexity within
  hss_generate.c is logic to try to work with multiple threads efficiently),
  however it's better than embedding conditional pthread calls throughout
  the code.  This hss_thread API allows us to issue "tasks"; these tasks may
  be run by the main thread or may be run in a spawned thread; the only
  guarantee is that, by the time hss_thread_done returns, all the tasks have
  completed.  Now, we provide two different implementations of this API; a
  trivial one (hss_thread_single.c), which doesn't try to spawn any threads,
  and one that assumes the POSIX pthread API (hss_thread_pthread.c), which
  makes calls to the pthread library to do this.  You're expected to link
  either one or the other when compiling the subsystem (and the Makefile we
  provide generates two libraries, hss_lib.a and hss_lib_thread.a, which does
  that for you).  We do this, rather than attempting some internal switch,
  because hss_thread_pthread.c makes direct calls to pthread (hence, would be
  a link error if the OS didn't provide some implementation of those).  Also,
  if you're interesting in supporting some other threading library (such as
  the one defined in C11), that shouldn't be that hard to add; we really use
  only the basics of what a threading library ought to provide.
  Also, as for avoiding race conditions (always a good idea), we have the
  convention that, when a task is writing the result, and the area it's
  writing to is malloc'ed or automatic region that might be shared by
  other threads, that task must call hss_thread_before_write(col) before the
  write (and hss_thread_after_write(col) afterwards); this makes sure that the
  thread is the only one to write into that region.  We do this even if two
  threads aren't actually updating the exact same bytes; because we're not
  careful to make sure our fields are aligned with the natural word size
  of the CPU (whatever that is), then what an update of one field might
  end up doing is a read/modify/write of a larger word, which might end
  up overlapping the target of another thread (which might be doing a
  read/modify/write of the same larger word simultaneously).  This is a rather
  unlikely event, however the race condition it would cause if it did happen
  would be *really* hard to track down.  Now, hss_thread_before_write does a
  lock, which means that no other thread can write into the common region
  until we release the lock, hence the time any thread holds the lock ought to
  be short; the current code abides by that.
  Now, we allow the application to specify the number of threads; if we're
  using the pthread library, that's the number of child threads we'll
  attempt to spawn (we don't count the parent thread, however while child
  threads are active, the parent thread doesn't do much).   Of course, it
  is subject to a sane maximum.  If the number of threads is specified as
  1, we'll fall back to single-threaded mode.  If it specifies 0, it gets
  a supposedly-reasonable default (DEFAULT_THREAD).  On the other hand, if
  we're linked with the nonthreaded library, this doesn't do anything (we're
  always in single-threaded mode).
  The obvious question is: how is the application supposed to know how
  many threads are appropriate?  I don't have a great answer to that.
  The number of threads you want are dependent on the number of cores
  you have on the system (spawning more than that just gives the OS a
  bit of a workout without speeding anything; after all, all the threads
  are CPU-bound), and how much of the system resources you want to devote to
  this task.  The pthread virtualization doesn't give us a hint on the first
  one; the second one is something the application might have a clue about.
  Also, while the key generation and loading can take advantage of as many
  threads as they can get, the signature generation and verification logic
  can't.  The signature generation logic is limited by the number of subtree
  levels in the bottom merkle tree (possibly times 2 if you're doing fault
  hardening), plus one; the signature verification logic is limited to the
  number of merkle levels.

- Use of malloc
  If you go through the code, you'll see an occasional call to malloc.  In
  allocate_working_key (hss_alloc.c), we use malloc to build the working key
  structure, and we'll fail (return 0) on a malloc failure.  The working key
  structure will contain everything we need to generate signatures (so we
  never *have* to do a malloc later).  Now, we will try to perform malloc's
  elsewhere, however they are always strictly optional; we'll never fail
  because malloc objected.  Instead, the code will step to a "plan B" on a
  failure, which will do the exact same job (but slower; if it wasn't slower,
  it wouldn't be plan B).
  The testing code (and demo.c) does use malloc, and will fail if the
  malloc fails; these tools can be expected to run only when we have plenty
  of memory, hence we feel we don't need a plan B there.

- Use of Variable Length Arrays
  We used to use VLAs (a C99 language feature) at places.  However, someone's
  compiler couldn't handle them (even though it implemented the rest of the
  C99 features we used), and so we went and reworked the code to remove them.
  In any case, removing the VLAs might make this code a bit more
  small-end-device friendly (as those small devices tend not to have huge
  stacks).

- Zeroization
  Whenever we're done with a value whose leakage might allow someone to
  generate a forgery, we zeroize it (hss_zeroize) before we release the
  memory.  Now, it turns out that most of the values we compute wouldn't
  actually allow a forgery; the ones that do are: the seeds, the OTS private
  keys and the OTS previous winternitz chain values.  We also zeroize the
  aux data HMAC values (those wouldn't allow a forgery; they would allow
  someone to cause us to misbehave by modifying the aux data).

- Use of globals
  There are no globals (other than the optional debugging flag hss_verbose
  and instrumentation code, such as hash_fault_*).  All memory is either a
  buffer provided by the calling application, dynamically allocated (malloc),
  or automatic (stack).  Globals are evil, reentrancy is good.  The regression
  code does have globals (for things like coordinating with the randomness
  generator; no normal program has any need for that); the regression code
  isn't intended for use for other programs...

- Use of floating point
  Crypto code hardly ever uses floating point (except perhaps to speed up
  integer multiplication).  However, we're an exception; in the hss_generate.c
  function, we do actually do some float point computations; we do this to
  figure out a reasonable way to split the building task between threads (and
  for this task, the imprecision inherent in floating point is not a problem;
  if two ways of splitting the task are so close in cost that the rounding
  error actually makes a difference, it doesn't really matter which way we
  go).  Now, we include a macro (DO_FLOATING_POINT) which disables the use of
  floating point; a platform that does not support floating point can set it
  to 0, and that code is commented out.  Now, if you use threading, you really
  want DO_FLOATING_POINT If you don't, it doesn't matter for performance, and
  actually, turing it off comments out quite a bit of code that you doesn't
  actually buy you anything; it doesn't matter how we divide tasks between
  threads if the same thread will end up performing them all anyways...
  We also use floating point in the regression code; to figure out when to
  update the displayed % completed.

- Debugging
  Good luck...

- Instrumentation
  config.h has a TEST_INSTRUMENTATION flag; if turned on, this enables some
  additional test infrastructure that allows us to test various error
  conditions.  This instrumentation should never be enabled in release code;
  it does allow the regression tests to check out some corner cases.
  Currently, the instrumentation code enables two things.
  - It enables malloc checking; it does some simple checks of the malloc's
    and free's (making sure we don't assume a zero malloc buffer, checking
    for free'ing correctness (e.g. no double free's), buffer
    overwrites/underwrites, and memory leaks.  The API we use internally
    is in hss_malloc.h; if TEST_INSTRUMENTATION is off, hss_malloc and
    hss_free calls are directly translated into malloc and free.
  - It allows us to inject hash failures; that is, at a controllable time, our
    code can miscompute a hash.  Obviously this need not be in a release
    version; it is useful if we want to double-check whether our
    fault-hardening code is working as advertised.  The API used is in
    hss_fault.h, along with the global hss_fault_enabled.  The
    hss_fault_enabled is the overall mode; with 0 being "never fault", 1 being
    "fault at the specified time", and 2 being "always fault".  In the case of
    hash_fault_enabled == 1, we characterize the hashes based on level (which
    is the Merkle tree level within the HSS hierarchy, with 0 being the
    topmost; 0 is used for hashes computed outslide the HSS hierarchy), and
    hash_fault_reason being the reason we're doing the hash (and hss_fault.h
    lists 9 different cateogiies).  We characterize hashes this way so that
    test_fault.c can tareget specific hashes (and test failures across the
    hierarchy).  In the code, we'll call hss_set_level(int) when we know we'll
    be working at s specific HSS level (and mostly we don't pass the level to
    the low level routines, so a higher level routine generally does the
    call); when we know which hash we're doing, we'll call
    hss_set_hash_reason.

- Regression tests
  This package includes the test_hss executable, which is meant to be a set
  of regression tests for this package.  It ought to be run early and often
  (with "test_hss all" being a good default), if not in -full mode, it's
  relatively quick.
  We've include the fault and the malloc tests; both run only if the
  instrumentation code is enabled (as both rely on additional testing code not
  in the release version); in addition, the fault test only if fault
  protection is enabled (the test is designed to test the effectiveness of
  fault protection, and it'll fail if it's not present).
  If the instrumentation is on, we will (at the end of the tests) check to
  see if there were any memory leaks (and if so, announce thar).

  The usage is:
      test_hss [-f] [-q] [-full] test_1 test_2 test_3
  Without any parameters, it gives a usage message (and the list of the
  supported tests)
  The parameters are:
  -f     Normally, this test suite stops at the first failure; with this flag
         it keeps on going
  -q     Normally, some of the longer tests some minimal progress messages
         (percent complete); with this flag, it just lists the test being run
         and a pass/fail message (and possibly a failure reason).
  -full  Normally, each test takes no more than 15 seconds to run (to
         encourage you to run it early and often).  With this flag, we allow
         the tests to run much longer; warning, it'll take several hours to
         run the full test suite in -full mode.  I'm also not convinced that
         -full mode gives you that much better coverage, on the other hand,
         it really has found problems that the short tests haven't, and so it
         should be run occasionally
  all    This is a shorthand to specify every test the test suite knows about.
         On my test machine, 'test_hss all' currently takes about 70 seconds.

  Now, there are things that the regression tests currently don't test:
  - Do we handle malloc failures as designed?
  - How about thread spawn failures?  We're supposed to handle those
    transparently
  - We're supposed to be able to limit the number of times we hash any
    specific secret; do we actually abide by that?
  - We're supposed to zeroize anything that would allow a forgery before
    freeing it; do we do so?
  Testing those would require more infrastructure than we have right now
  (although inserting those based on the TEST_INSTRUMENTATION flag would
  be the obvious place to start).
  Also, it might not be that bad of an idea to run a code-coverage tool to
  check out how much of the code the regression tests actually tests.

- Files; this is a listing of the files that make up this subsystem, and a
  brief description of what's in them.  Note that for many .c files, we have a
  .h file with the prototypes; we list those together.

  common_defs.h		This is a central spot to put definitions of general
			interest of the entire subsystem
  config.h              Common file that contains configurable options that
                        the user may wish to tweak
  demo.c		This is an example program that uses this subsystem; it
			implements a simple file signer.  Note: because it
			doesn't get that great of randomness (due to the need
			to restrict ourselves to standard C), it probably
			shouldn't be used as is.  It does try to use
			/dev/urandom; that's of help only on OS's that
			actually implement /dev/urandom
  endian.[ch]		Routines to read/write values in bigendian format
  hash.[ch]		Routines to implement the hashing API, as used by the
			rest of the subsystem.  This currently only implements
			SHA-256, it'll support other hashes once LMS does.
			Note that there really are three separate APIs to do
			hashing (hash this entire string, hash this string
			using this context variable as a temp, do on-line
			hashing); those are all used at various times.
  hss.c			This used to be where all the code lived; however, we
			have since migrated the vast majority of the routines
			to more appropriate source files (so we don't have a
			huge .c file).  Now, it just has a handful of routines
			that don't have a better home.
  hss.h			This is the public include file for the entire
			subsystem; this is the file that we expect an
		 	application that uses this subsystem to include.
  hss_alloc.c		This is the routine whose job it is to allocate a
			working key (struct hss_working_key).  Note that it
			doesn't actually put anything in there, it just
			allocates the memory (and initializes some
			key-independent fields).
  hss_aux.[ch]		These are the routines that handle auxiliary data (that
			is, data that holds part of the top level Merkle tree,
			and is used to speed up the key load process)
  hss_common.c		These are routines that are of interest to both an
			implementation that generates signatures, and one that
			only does signature verification.
  hss_common.h		These are the prototypes for the above routines; we
			list it separately to emphesize that this may be
			included by an application.
  hss_compute.[ch]	These are routines that do some common computation;
			these are shared between multiple source files.
  hss_derive.[ch]	This is the structure that does key derivation.  It
			allows a trade-off between efficiency, and side channel
			resistance.
  hss_fault.h           This contains the interface to the fault error
                        injection logic; that is, routines that various
                        functions use to declare why they're doing a hash.
                        This information allows the error injection logic
                        to target a specific hash location (rather than making
                        a random hash fail).  The actual code to do fault
                        error injection is in hash.c
  hss_generate.c	This is the routine that takes an allocated working key
			(hss_alloc.c), and loads a private key into it.  Sound
			simple?  Well, if you go through this, you'll find out
			that it isn't.
  hss_internal.h	These are the prototypes and structures that are common
			to this subsystem, but shouldn't be used outside of it.
  hss_keygen.c		This is the routine that generates a public/private
			keypair.
  hss_malloc.[ch]	These are routines that do our instrumented checking
			of malloc/free.  If instrumentation is turned off, calls
			are directly routed to the standard malloc/free.
  hss_param.c		These are routines that deal with parameter sets.
  hss_reserve.[ch]	These are routines that deal with reservations, and
			updating the sequence number in a private key.
  hss_sign.c		This is the routine that generates an HSS signature.
  hss_sign_inc.c	This is the routine that generates an HSS signature,
                        in an incremental fashion.
  hss_sign_inc.h        This is the public include file for the incremental
                        signature routines.  It's in its own file because it
                        needs to pull in some internal files (e.g. hash.h)'
                        that we generally don't need to hand to people
  hss_thread.h		This is the internal prototype for our internal
			threading abstraction.  We have two implementations of
			the abstraction, we expect to link with one of the two.
  hss_thread_pthread.c	This is the implementation of the threading API that
			links with the POSIX pthread library, and uses that to
			to multithreading.
  hss_thread_single.c	This is the implementation of the threading API that
			assumes that we don't have any threading support at all
			(and so the main thread does all the work).
  hss_verify.c		This is the routine that verifies an HSS signature.  It
			is in its own file so thar someone who wants to only
			verify signatures doesn't need to pull in the signing
			logic.
  hss_verify.h		This is the public API for the verifier.
  hss_verify_inc.c	This is the routine that verifies an HSS signature in
			an incremental fashion; that is, you can hand it
			pieces of the message in succession (so we don't need
			to assume the entire message fits in memory).  It
			is in its own file so thar someone who wants to only
			verify signatures doesn't need to pull in the signing
			logic.  This API is somewhat less efficient that the
                        hss_verify.c logic if you're multithreaded (we can't
                        paralleize the check of the bottom signature with
                        the upper ones), however it's not a huge delta.
  hss_verify_inc.h	This is the public API for the incremental verifier.
			It's in its own file because it needs to pull in some
			internal files (e.g. hash.h) that we generally don't
			need to hand to people
  hss_zeroize.[ch]	This is a routine to clear out memory; it is used to
			make sure we don't accidently leak any secrets by
			free()ing them, or having them go out of scope.
  lm_common.[ch]	These are routines that support the (single level) LMS
			routines that are of interest to both an implementation
			that generates signatures, and one that only does
			signature verification.
  lm_ots.h		Prototype for the OTS signature routines.
  lm_ots_common.[ch]	These are routines that support the OTS routines that
			are of interest to both an implementation that
			generates signatures, and one that only does
			signature verification.
  lm_ots_sign.c		Routines that generate OTS public keys, and OTS
			signatures
  lm_ots_verify.c	Routine that computes the public key given an OTS
			signature and a message.
  lm_verify.[ch]	Routine that verifies an LMS signature
  sha256.c		Pure C implementation of SHA-256; it is included if
			USE_OPENSSL is 0.  This is provided in case you don't
			have OpenSSL available.
  sha256.h		Routine that computes the SHA-256 hash.  This is the
			same interface that OpenSSL presents.  We also
			include a #define (USE_OPENSSL); if 1, these are
			direct calls to OpenSSL; if 0, we use our own
			implementation (in case you don't have OpenSSL
			handy).  If OpenSSL is available, use that - it has
			an assembly language SHA-256 implementation, and that
			performs better.
   test_hss.c           This is the main driver code for the regression tests.
                        It doesn't actually implement any tests itself;
                        instead, it deals with handling the test run
   test_hss.h           This has the prototypes for all the actual tests
   test_*.c             These are the actual tests.

And, one final note: I would claim to be a competent C programmer, however my
skills at generating makefiles are laughable.  I would ask that you keep the
taunting about my lack of ability there to reasonable bounds.
